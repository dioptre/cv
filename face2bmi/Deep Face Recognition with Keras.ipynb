{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "https://sefiks.com/2018/08/06/deep-face-recognition-with-keras/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network configuration\n",
    "\n",
    "Even though research paper is named Deep Face, researchers give VGG-Face name to the model. This might be because Facebook researchers also called their face recognition system DeepFace – without blank. VGG-Face is deeper than Facebook’s Deep Face, it has 22 layers and 37 deep units.\n",
    "\n",
    "The structure of the VGG-Face model is demonstrated below. Only output layer is different than the imagenet version – you might compare.\n",
    "\n",
    "![image](https://i0.wp.com/sefiks.com/wp-content/uploads/2018/08/vgg-face-model.png?ssl=1)\n",
    "VGG-Face model\n",
    "![image](https://i0.wp.com/sefiks.com/wp-content/uploads/2019/04/vgg-face-architecture.jpg?w=1805&ssl=1)\n",
    "Visualization of VGG-Face\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract VGG-Face Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import ZeroPadding2D, Convolution2D, MaxPooling2D, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=(224, 224))\n",
    "    img = img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = preprocess_input(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(input, output = None):\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1,1),input_shape=(224,224, 3)))\n",
    "    model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(Convolution2D(4096, (7, 7), activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Convolution2D(4096, (1, 1), activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Convolution2D(2622, (1, 1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.load_weights('./weights/vgg_face_weights.h5')\n",
    "    \n",
    "    vgg_face_descriptor = Model(\n",
    "    inputs=model.layers[0].input,\n",
    "    outputs=model.layers[-2].output)\n",
    "    \n",
    "    print('converting images from %s'%(input))\n",
    "    face_array_representation = {}\n",
    "    if os.path.isdir(input):\n",
    "        for img_name in tqdm(os.listdir(input)):\n",
    "            face_array_representation[img_name] = vgg_face_descriptor.predict(preprocess_image('{}/{}'.format(input,img_name)))[0,:]\n",
    "    if os.path.isfile(input):\n",
    "        img_name = input.split('/')[-1]\n",
    "        face_array_representation[img_name] = vgg_face_descriptor.predict(preprocess_image('{}'.format(input)))[0,:]\n",
    "    if output == None:\n",
    "        return face_array_representation\n",
    "    # save array to pickle\n",
    "    print('output array to {}'.format(output))\n",
    "    with open(output,'wb') as f:\n",
    "        pickle.dump(face_array_representation, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 883/883 [18:21<00:00,  1.25s/it]\n"
     ]
    }
   ],
   "source": [
    "extract_feature(input = './face', output = './face_array_representation.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting images from ./test/0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:12<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output array to ./face_array_test.pkl\n"
     ]
    }
   ],
   "source": [
    "extract_feature(input='./test/0', output='./face_array_test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Regression Model using extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./face_array_representation.pkl','rb') as f:\n",
    "    loaded_face_array = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2612</th>\n",
       "      <th>2613</th>\n",
       "      <th>2614</th>\n",
       "      <th>2615</th>\n",
       "      <th>2616</th>\n",
       "      <th>2617</th>\n",
       "      <th>2618</th>\n",
       "      <th>2619</th>\n",
       "      <th>2620</th>\n",
       "      <th>2621</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>248038.jpg</th>\n",
       "      <td>1.571467</td>\n",
       "      <td>-0.671615</td>\n",
       "      <td>-1.159301</td>\n",
       "      <td>1.293227</td>\n",
       "      <td>-0.093556</td>\n",
       "      <td>-0.697550</td>\n",
       "      <td>0.148561</td>\n",
       "      <td>0.685544</td>\n",
       "      <td>0.704531</td>\n",
       "      <td>-0.749262</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.834303</td>\n",
       "      <td>-0.444321</td>\n",
       "      <td>-2.283065</td>\n",
       "      <td>0.731417</td>\n",
       "      <td>-0.269255</td>\n",
       "      <td>-0.156841</td>\n",
       "      <td>-1.303293</td>\n",
       "      <td>-1.313362</td>\n",
       "      <td>1.072968</td>\n",
       "      <td>0.399883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250464.jpg</th>\n",
       "      <td>4.145911</td>\n",
       "      <td>-0.537042</td>\n",
       "      <td>0.426129</td>\n",
       "      <td>-0.076368</td>\n",
       "      <td>-1.404314</td>\n",
       "      <td>5.505557</td>\n",
       "      <td>1.766905</td>\n",
       "      <td>-0.137578</td>\n",
       "      <td>-0.028811</td>\n",
       "      <td>1.579135</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.207776</td>\n",
       "      <td>-0.165933</td>\n",
       "      <td>0.203628</td>\n",
       "      <td>3.507101</td>\n",
       "      <td>0.909248</td>\n",
       "      <td>-1.001198</td>\n",
       "      <td>-4.078630</td>\n",
       "      <td>-2.369386</td>\n",
       "      <td>2.183077</td>\n",
       "      <td>1.695219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263711.jpg</th>\n",
       "      <td>3.517062</td>\n",
       "      <td>-1.236114</td>\n",
       "      <td>0.551771</td>\n",
       "      <td>1.814112</td>\n",
       "      <td>0.669282</td>\n",
       "      <td>1.231691</td>\n",
       "      <td>-0.022512</td>\n",
       "      <td>1.994583</td>\n",
       "      <td>0.180609</td>\n",
       "      <td>-0.126408</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.078979</td>\n",
       "      <td>-0.967290</td>\n",
       "      <td>-2.290201</td>\n",
       "      <td>2.092639</td>\n",
       "      <td>-0.915509</td>\n",
       "      <td>-2.594831</td>\n",
       "      <td>-2.218287</td>\n",
       "      <td>-0.608502</td>\n",
       "      <td>-1.127747</td>\n",
       "      <td>1.167402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270020.jpg</th>\n",
       "      <td>1.655680</td>\n",
       "      <td>1.908274</td>\n",
       "      <td>1.573434</td>\n",
       "      <td>0.921428</td>\n",
       "      <td>0.585250</td>\n",
       "      <td>4.087645</td>\n",
       "      <td>3.144320</td>\n",
       "      <td>1.453200</td>\n",
       "      <td>2.634692</td>\n",
       "      <td>1.265123</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.545173</td>\n",
       "      <td>0.093986</td>\n",
       "      <td>-1.480046</td>\n",
       "      <td>2.034657</td>\n",
       "      <td>1.998626</td>\n",
       "      <td>-0.455827</td>\n",
       "      <td>-1.490269</td>\n",
       "      <td>-4.067970</td>\n",
       "      <td>2.701385</td>\n",
       "      <td>4.466756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277774.jpg</th>\n",
       "      <td>2.165415</td>\n",
       "      <td>0.742228</td>\n",
       "      <td>-0.558265</td>\n",
       "      <td>2.981857</td>\n",
       "      <td>0.493239</td>\n",
       "      <td>2.308912</td>\n",
       "      <td>1.586248</td>\n",
       "      <td>3.301033</td>\n",
       "      <td>1.498757</td>\n",
       "      <td>2.043516</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.973742</td>\n",
       "      <td>-0.532828</td>\n",
       "      <td>-1.948492</td>\n",
       "      <td>0.832768</td>\n",
       "      <td>1.065996</td>\n",
       "      <td>-2.232458</td>\n",
       "      <td>-3.791786</td>\n",
       "      <td>-0.385528</td>\n",
       "      <td>1.631693</td>\n",
       "      <td>2.910033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2622 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1         2         3         4         5     \\\n",
       "248038.jpg  1.571467 -0.671615 -1.159301  1.293227 -0.093556 -0.697550   \n",
       "250464.jpg  4.145911 -0.537042  0.426129 -0.076368 -1.404314  5.505557   \n",
       "263711.jpg  3.517062 -1.236114  0.551771  1.814112  0.669282  1.231691   \n",
       "270020.jpg  1.655680  1.908274  1.573434  0.921428  0.585250  4.087645   \n",
       "277774.jpg  2.165415  0.742228 -0.558265  2.981857  0.493239  2.308912   \n",
       "\n",
       "                6         7         8         9     ...      2612      2613  \\\n",
       "248038.jpg  0.148561  0.685544  0.704531 -0.749262  ... -1.834303 -0.444321   \n",
       "250464.jpg  1.766905 -0.137578 -0.028811  1.579135  ... -0.207776 -0.165933   \n",
       "263711.jpg -0.022512  1.994583  0.180609 -0.126408  ... -1.078979 -0.967290   \n",
       "270020.jpg  3.144320  1.453200  2.634692  1.265123  ... -0.545173  0.093986   \n",
       "277774.jpg  1.586248  3.301033  1.498757  2.043516  ... -1.973742 -0.532828   \n",
       "\n",
       "                2614      2615      2616      2617      2618      2619  \\\n",
       "248038.jpg -2.283065  0.731417 -0.269255 -0.156841 -1.303293 -1.313362   \n",
       "250464.jpg  0.203628  3.507101  0.909248 -1.001198 -4.078630 -2.369386   \n",
       "263711.jpg -2.290201  2.092639 -0.915509 -2.594831 -2.218287 -0.608502   \n",
       "270020.jpg -1.480046  2.034657  1.998626 -0.455827 -1.490269 -4.067970   \n",
       "277774.jpg -1.948492  0.832768  1.065996 -2.232458 -3.791786 -0.385528   \n",
       "\n",
       "                2620      2621  \n",
       "248038.jpg  1.072968  0.399883  \n",
       "250464.jpg  2.183077  1.695219  \n",
       "263711.jpg -1.127747  1.167402  \n",
       "270020.jpg  2.701385  4.466756  \n",
       "277774.jpg  1.631693  2.910033  \n",
       "\n",
       "[5 rows x 2622 columns]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_face_feature = pd.DataFrame(loaded_face_array).T\n",
    "df_face_feature.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>book_date</th>\n",
       "      <th>bookid</th>\n",
       "      <th>city</th>\n",
       "      <th>eyes</th>\n",
       "      <th>hair</th>\n",
       "      <th>height</th>\n",
       "      <th>holding_location</th>\n",
       "      <th>name</th>\n",
       "      <th>nameid</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>weight</th>\n",
       "      <th>bmi</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54</td>\n",
       "      <td>3/10/2017 10:05:55 AM</td>\n",
       "      <td>248038</td>\n",
       "      <td>WAUKEE, IA</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Black</td>\n",
       "      <td>71.0</td>\n",
       "      <td>PCJ</td>\n",
       "      <td>JAMES DEYO ROBINSON</td>\n",
       "      <td>7482</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>280</td>\n",
       "      <td>39.047808</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "      <td>4/23/2017 8:57:43 AM</td>\n",
       "      <td>250464</td>\n",
       "      <td>DES MOINES, IA</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Black</td>\n",
       "      <td>71.0</td>\n",
       "      <td>Cherokee Mental Health</td>\n",
       "      <td>CORDERRO ALTON LAURENCE</td>\n",
       "      <td>754952</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>210</td>\n",
       "      <td>29.285856</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>12/7/2017 4:00:07 PM</td>\n",
       "      <td>263711</td>\n",
       "      <td>DES MOINES, IA</td>\n",
       "      <td>Green</td>\n",
       "      <td>Blonde</td>\n",
       "      <td>69.0</td>\n",
       "      <td>PCJ</td>\n",
       "      <td>TAYLOR LOUIS HARLAN</td>\n",
       "      <td>644421</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>290</td>\n",
       "      <td>42.820836</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>4/1/2018 3:24:44 AM</td>\n",
       "      <td>270020</td>\n",
       "      <td>DES MOINES, IA</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Black</td>\n",
       "      <td>63.0</td>\n",
       "      <td>PCJ</td>\n",
       "      <td>MALIK TYRONE MANDUJANO</td>\n",
       "      <td>699804</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>130</td>\n",
       "      <td>23.025951</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>8/5/2018 9:26:54 PM</td>\n",
       "      <td>277774</td>\n",
       "      <td>DES MOINES, IA</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blonde</td>\n",
       "      <td>74.0</td>\n",
       "      <td>PCJ</td>\n",
       "      <td>DUSTIN GLEN BLACK</td>\n",
       "      <td>238047</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>230</td>\n",
       "      <td>29.527027</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age              book_date  bookid            city   eyes    hair  height  \\\n",
       "0   54  3/10/2017 10:05:55 AM  248038      WAUKEE, IA  Brown   Black    71.0   \n",
       "1   26   4/23/2017 8:57:43 AM  250464  DES MOINES, IA  Brown   Black    71.0   \n",
       "2   24   12/7/2017 4:00:07 PM  263711  DES MOINES, IA  Green  Blonde    69.0   \n",
       "3   21    4/1/2018 3:24:44 AM  270020  DES MOINES, IA  Brown   Black    63.0   \n",
       "4   29    8/5/2018 9:26:54 PM  277774  DES MOINES, IA   Blue  Blonde    74.0   \n",
       "\n",
       "         holding_location                     name  nameid   race   sex  \\\n",
       "0                     PCJ      JAMES DEYO ROBINSON    7482  Black  Male   \n",
       "1  Cherokee Mental Health  CORDERRO ALTON LAURENCE  754952  Black  Male   \n",
       "2                     PCJ      TAYLOR LOUIS HARLAN  644421  White  Male   \n",
       "3                     PCJ   MALIK TYRONE MANDUJANO  699804  Black  Male   \n",
       "4                     PCJ        DUSTIN GLEN BLACK  238047  White  Male   \n",
       "\n",
       "   weight        bmi  label  \n",
       "0     280  39.047808      1  \n",
       "1     210  29.285856      0  \n",
       "2     290  42.820836      1  \n",
       "3     130  23.025951      0  \n",
       "4     230  29.527027      0  "
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./full_coded.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_TRAIN_RATIO = 0.8\n",
    "df['img_name'] = df.bookid.map(lambda i: str(i)+'.jpg')\n",
    "df = df[['age','sex','race','height','weight','bmi', 'img_name']]\n",
    "in_train = np.random.uniform(size = len(df)) <= IN_TRAIN_RATIO\n",
    "df_train = df.loc[in_train,:]\n",
    "df_valid = df.loc[~in_train,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(708, 7)\n",
      "(183, 7)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "print(df_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[['img_name','age']].set_index('img_name').join(df_face_feature)\n",
    "df_valid = df_valid[['img_name','age']].set_index('img_name').join(df_face_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics.regression import mean_squared_error, mean_absolute_error, r2_score\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.iloc[:,1:].values\n",
    "y = df_train.iloc[:,0].values\n",
    "X[np.isnan(X)] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = df_valid.iloc[:,1:].values\n",
    "y_valid = df_valid.iloc[:,0].values\n",
    "X_valid[np.isnan(X_valid)] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_object(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        res = pickle.load(f)\n",
    "    return res\n",
    "\n",
    "def save_object(obj, file):\n",
    "    with open(file, 'wb') as f:\n",
    "        pickle.dump(obj, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = linear_model.Lasso(alpha=0.2)\n",
    "model_reg = reg.fit(X,y)\n",
    "y_pred = model_reg.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 6.934\n",
      "mae: 5.560\n",
      "r2: 0.643\n",
      "cor: 0.803 with p-valud 0.000\n"
     ]
    }
   ],
   "source": [
    "print('rmse: %5.3f'%(mean_squared_error(y_valid, y_pred) ** 0.5))\n",
    "print('mae: %5.3f'%(mean_absolute_error(y_valid, y_pred)))\n",
    "print('r2: %5.3f'%(r2_score(y_valid, y_pred)))\n",
    "print('cor: %5.3f with p-valud %0.3f'%(pearsonr(y_valid, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1dae8c31908>"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(y_pred).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_object(model_reg, './saved_model/lasso_model_age.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-rmse:36.0792\ttrain-rmse:35.3741\n",
      "Multiple eval metrics have been passed: 'train-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until train-rmse hasn't improved in 21 rounds.\n",
      "[50]\teval-rmse:23.6531\ttrain-rmse:22.1827\n",
      "[100]\teval-rmse:16.3298\ttrain-rmse:14.035\n",
      "[150]\teval-rmse:12.1984\ttrain-rmse:8.97414\n",
      "[200]\teval-rmse:9.96115\ttrain-rmse:5.82595\n",
      "[250]\teval-rmse:8.82305\ttrain-rmse:3.87669\n",
      "[300]\teval-rmse:8.23025\ttrain-rmse:2.68664\n",
      "[350]\teval-rmse:7.92862\ttrain-rmse:1.98597\n",
      "[400]\teval-rmse:7.768\ttrain-rmse:1.59888\n",
      "[450]\teval-rmse:7.6778\ttrain-rmse:1.39829\n",
      "[500]\teval-rmse:7.62649\ttrain-rmse:1.29926\n",
      "[550]\teval-rmse:7.59756\ttrain-rmse:1.2521\n",
      "[600]\teval-rmse:7.57944\ttrain-rmse:1.22972\n",
      "[650]\teval-rmse:7.56681\ttrain-rmse:1.21883\n",
      "[700]\teval-rmse:7.55816\ttrain-rmse:1.21344\n",
      "[750]\teval-rmse:7.55251\ttrain-rmse:1.21066\n",
      "[800]\teval-rmse:7.5488\ttrain-rmse:1.20915\n",
      "[850]\teval-rmse:7.54651\ttrain-rmse:1.20832\n",
      "[900]\teval-rmse:7.5449\ttrain-rmse:1.20785\n",
      "[950]\teval-rmse:7.54393\ttrain-rmse:1.20755\n",
      "[999]\teval-rmse:7.54319\ttrain-rmse:1.20737\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(X,label=y)\n",
    "dvalid = xgb.DMatrix(X_valid, label=y_valid)\n",
    "param = {'max_depth':9, 'eta':0.01, 'objective':'reg:squarederror', 'silent':0, 'colsample_bytree':0.3}\n",
    "watchlist = [(dvalid, 'eval'), (dtrain, 'train')]\n",
    "num_round = 1000\n",
    "bst = xgb.train(param, dtrain, num_round, \n",
    "                evals = watchlist, \n",
    "                early_stopping_rounds=21, \n",
    "               verbose_eval=50,)\n",
    "y_pred = bst.predict(dvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 4.665\n",
      "mae: 3.521\n",
      "r2: 0.241\n",
      "cor: 0.512 with p-valud 0.000\n"
     ]
    }
   ],
   "source": [
    "print('rmse: %5.3f'%(mean_squared_error(y_valid, y_pred) ** 0.5))\n",
    "print('mae: %5.3f'%(mean_absolute_error(y_valid, y_pred)))\n",
    "print('r2: %5.3f'%(r2_score(y_valid, y_pred)))\n",
    "print('cor: %5.3f with p-valud %0.3f'%(pearsonr(y_valid, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1dae7a27240>"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(y_pred).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_bmi(model, face_array):\n",
    "    \"\"\" predcit bmi from face array or face array path (pickle file)\n",
    "    Args: face_array (dict or path string)\n",
    "    Return: BMI in float\n",
    "    \"\"\"\n",
    "\n",
    "    if type(face_array) == str:\n",
    "        with open(face_array,'rb') as f:\n",
    "            face_array = pickle.load(f)\n",
    "    \n",
    "    df_test = pd.DataFrame(face_array).T\n",
    "    res = pd.DataFrame({'name': df_test.index.tolist(), \n",
    "              'bmi_predicted':model.predict(df_test.values)})\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>bmi_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>barack-obama.jpg</td>\n",
       "      <td>46.147903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clinton-3.jpg</td>\n",
       "      <td>64.415108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>emma_watson.jpg</td>\n",
       "      <td>29.875290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kent_cheng.jpg</td>\n",
       "      <td>38.217903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kent_zheng.jpg</td>\n",
       "      <td>30.169107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>leonardo1.jpeg</td>\n",
       "      <td>38.127434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Leonardo_Dicaprio_Cannes_2019.jpg</td>\n",
       "      <td>58.052757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>trump.jpg</td>\n",
       "      <td>71.882805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>xi.jpg</td>\n",
       "      <td>52.036121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                name  bmi_predicted\n",
       "0                   barack-obama.jpg      46.147903\n",
       "1                      clinton-3.jpg      64.415108\n",
       "2                    emma_watson.jpg      29.875290\n",
       "3                     kent_cheng.jpg      38.217903\n",
       "4                     kent_zheng.jpg      30.169107\n",
       "5                     leonardo1.jpeg      38.127434\n",
       "6  Leonardo_Dicaprio_Cannes_2019.jpg      58.052757\n",
       "7                          trump.jpg      71.882805\n",
       "8                             xi.jpg      52.036121"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_bmi(model_reg, './face_array_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting images from ./test/0/me.jpg\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>bmi_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>me.jpg</td>\n",
       "      <td>25.878784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name  bmi_predicted\n",
       "0  me.jpg      25.878784"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_bmi(model_reg, extract_feature(input='./test/0/me.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face2bmi",
   "language": "python",
   "name": "face2bmi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
